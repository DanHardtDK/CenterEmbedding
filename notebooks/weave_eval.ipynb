{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import weave\n",
    "from weave import Model, Evaluation\n",
    "from pydantic import field_validator\n",
    "from configparser import ConfigParser\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = ConfigParser()\n",
    "config_parser.read(\"config.cfg\")\n",
    "LLAMA_KEY = config_parser.get(\"DEFAULT\", \"LLAMA_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Path(\"data/centerEmbed/ce1.json\").open(encoding=\"UTF-8\") as source:\n",
    "     objects = json.load(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama(Model):\n",
    "\n",
    "    model_name : str\n",
    "    api_key : str\n",
    "    prompt_template : str\n",
    "\n",
    "    @property\n",
    "    def api(self):\n",
    "        return OpenAI(\n",
    "            api_key=self.api_key, \n",
    "            base_url=\"https://api.llama-api.com\"\n",
    "        )\n",
    "    \n",
    "\n",
    "    def format(self, context : str, question : str, params : dict, **kwargs) -> dict:\n",
    "\n",
    "        prompt = self.prompt_template.format(context=context, question=question)\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            **params,\n",
    "            **kwargs\n",
    "        }\n",
    "\n",
    "    @weave.op()\n",
    "    async def predict(self, context : str, question : str, params : dict = {}, **kwargs):\n",
    "\n",
    "        payload = self.format(context, question, params, **kwargs)\n",
    "\n",
    "        response = await self.api.chat.completions.create(\n",
    "            model=self.model_name, \n",
    "            **payload\n",
    "        )\n",
    "        if response is None:\n",
    "            raise ValueError(\"No response from model\")\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"You will be given an example consisting of a context and a question to answer. The answer should always be of this form \"The N V the N\", where N stands for a single word that is a noun, and V stands for a single word that is a verb. \n",
    "Here are two samples:\n",
    "\n",
    "        \"Context\": \"The student the man noticed seemed happy\",\n",
    "        \"Question\": \"Who saw who?\",\n",
    "        \"Answer\": \"The man saw the student.\",\n",
    "\n",
    "\n",
    "        \"Context\": \"The teacher the student saw hit is dead\",\n",
    "        \"Question\": \"Who saw who?\",\n",
    "        \"Answer\": \"The student saw the teacher.\",\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Now answer the question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Llama(\n",
    "    name=\"llama-7b-chat\",\n",
    "    description=\"Weave model for Llama\",\n",
    "    model_name=\"llama-7b-chat\",\n",
    "    api_key=LLAMA_KEY,\n",
    "    prompt_template=PROMPT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_sample = objects[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for i, ex in enumerate(examples_sample):\n",
    "\n",
    "    examples.append(\n",
    "        {\n",
    "            \"id\": i,\n",
    "            \"context\": ex[\"Context\"],\n",
    "            \"question\": ex[\"Q\"],\n",
    "            \"target\": ex[\"A\"]\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define any custom scoring function\n",
    "@weave.op()\n",
    "def evaluator(target: dict, model_output: dict) -> dict:\n",
    "    # Here is where you'd define the logic to score the model output\n",
    "    return {'correct': target == model_output}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Context': 'The teacher the student saw is happy',\n",
       "  'Q': 'Who saw who?',\n",
       "  'A': 'the student saw the teacher.',\n",
       "  'level': '1'},\n",
       " {'Context': 'The teacher the student saw left',\n",
       "  'Q': 'Who saw who?',\n",
       "  'A': 'the student saw the teacher.',\n",
       "  'level': '1'}]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: nthomsen.\n",
      "View Weave data at https://wandb.ai/cbs-nlp/first_eval4/weave\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_output failed\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_output failed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/flow/eval.py\", line 110, in predict_and_score\n",
      "    model_output = await async_call(model_predict, **model_predict_args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nicolai/Desktop/cbs/research/CenterEmbedding/centerembed/lib/python3.12/site-packages/weave/trace/op.py\", line 113, in _run_async\n",
      "    output = await awaited_res\n",
      "             ^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/zm/ngjbkxbs3zv0psd22_khcy2w0000gn/T/ipykernel_11420/2386259436.py\", line 31, in predict\n",
      "    response = await self.api.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object ChatCompletion can't be used in 'await' expression\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m7\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m8\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m9\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> examples\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluated \u001b[1;36m10\u001b[0m of \u001b[1;36m10\u001b[0m examples\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'evaluator'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'correct'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.595898175239563</span><span style=\"font-weight: bold\">}}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Evaluation summary\n",
       "\u001b[1m{\u001b[0m\u001b[32m'evaluator'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'correct'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m2.595898175239563\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/cbs-nlp/first_eval4/r/call/32d4ad73-59cc-4953-8c9a-9f93939d9d55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'evaluator': {'correct': {'true_count': 0, 'true_fraction': 0.0}},\n",
       " 'model_latency': {'mean': 2.595898175239563}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.init(\"first_eval4\")\n",
    "\n",
    "\n",
    "################\n",
    "# SAMPLE EXAMPLES\n",
    "################\n",
    "\n",
    "sample: list = random.sample(examples, 10)\n",
    "\n",
    "################\n",
    "# RUN EVALUATION\n",
    "################\n",
    "\n",
    "evaluation = weave.Evaluation(\n",
    "    dataset=sample,\n",
    "    scorers=[evaluator]\n",
    ")\n",
    "\n",
    "await evaluation.evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
