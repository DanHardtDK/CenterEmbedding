{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import weave\n",
    "from weave import Model\n",
    "from pydantic import field_validator\n",
    "from configparser import ConfigParser\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_parser = ConfigParser()\n",
    "config_parser.read(\"config.cfg\")\n",
    "LLAMA_KEY = config_parser.get(\"DEFAULT\", \"LLAMA_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama(Model):\n",
    "\n",
    "    model_name : str\n",
    "    api_key : str\n",
    "    prompt : str\n",
    "\n",
    "    @property\n",
    "    def api(self):\n",
    "        return OpenAI(\n",
    "            api_key=self.api_key, \n",
    "            base_url=\"https://api.llama-api.com\"\n",
    "        )\n",
    "    \n",
    "\n",
    "    def format(self, payload : dict, params : dict, **kwargs) -> dict:\n",
    "\n",
    "        prompt = self.prompt.format(**payload)\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            **params,\n",
    "            **kwargs\n",
    "        }\n",
    "\n",
    "    @weave.op()\n",
    "    def predict(self, prompt: str, params : dict, **kwargs):\n",
    "        response = self.api.chat.completions.create(\n",
    "            model=self.model_name, \n",
    "            **self.format(prompt, params, **kwargs)\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "\n",
    "        if result is None:\n",
    "            raise ValueError(\"No response from model\")\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"You will be given an example consisting of a context and a question to answer. The answer should always be of this form \"The N V the N\", where N stands for a single word that is a noun, and V stands for a single word that is a verb. \n",
    "Here are two samples:\n",
    "\n",
    "        \"Context\": \"The student the man saw is happy\",\n",
    "        \"Question\": \"Who saw who?\",\n",
    "        \"Answer\": \"The man saw the student.\",\n",
    "\n",
    "\n",
    "        \"Context\": \"The teacher the student saw hit is happy\",\n",
    "        \"Question\": \"Who saw who?\",\n",
    "        \"Answer\": \"The student saw the teacher.\",\n",
    "\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Now answer the question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    \"context\": \"The dog the cat saw was happy\",\n",
    "    \"question\": \"Who saw who?\",\n",
    "    \"A\": \"The cat saw the dog.\",\n",
    "    \"level\": \"1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Llama(\n",
    "    name=\"llama-7b-chat\",\n",
    "    description=\"Weave model for Llama\",\n",
    "    model_name=\"llama-7b-chat\",\n",
    "    api_key=LLAMA_KEY,\n",
    "    prompt=PROMPT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Weights & Biases user: nthomsen.\n",
      "View Weave data at https://wandb.ai/cbs-nlp/first_try/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weave.init(\"first_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/cbs-nlp/first_try/r/call/9f0b274b-e97f-40d5-9cfa-684b2816a422\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(\n",
    "    example,\n",
    "    params={\"max_tokens\": 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat saw the dog.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output == example[\"A\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
